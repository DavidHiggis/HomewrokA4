{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ESRGAN_oldarch.ipynb","provenance":[{"file_id":"https://9github.com/shahidul56/ESRGAN/blob/master/ESRGAN.ipynb","timestamp":1564494511698}],"collapsed_sections":["jpxbz90LD9pu","t09P4RnqhOPR","FgdsmGxihSGf"],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"0zm3KgaEqiQV","colab_type":"code","outputId":"330ad17a-7343-4a7f-aca5-179107c7849e","executionInfo":{"status":"ok","timestamp":1581685098401,"user_tz":-480,"elapsed":59454,"user":{"displayName":"lamraq ituki","photoUrl":"","userId":"07547115291483367303"}},"colab":{"base_uri":"https://localhost:8080/","height":123}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_8yCGxILque_","colab_type":"code","outputId":"d6ddc84b-a501-44fd-d8df-dc1535c637d1","executionInfo":{"status":"ok","timestamp":1581422735707,"user_tz":-480,"elapsed":1732,"user":{"displayName":"lamraq ituki","photoUrl":"","userId":"07547115291483367303"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["cd /content/drive/My Drive/TFMLz/ESRGAN_oldarch"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/TFMLz/ESRGAN_oldarch\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"FJGwneRJq0Dn","colab_type":"text"},"source":["# YUVups"]},{"cell_type":"code","metadata":{"id":"hdrnHaqVq7q2","colab_type":"code","outputId":"85199913-4451-4454-a600-59d7cdf95465","executionInfo":{"status":"ok","timestamp":1581685174381,"user_tz":-480,"elapsed":53041,"user":{"displayName":"lamraq ituki","photoUrl":"","userId":"07547115291483367303"}},"colab":{"base_uri":"https://localhost:8080/","height":155}},"source":["zirr = 'V004_b'\n","wrkbase = '/content/'\n","\n","%cd /content\n","!git clone https://github.com/IbrahimKurz/{zirr}.git\n","!chmod 755 /content/{zirr}/README.sh\n","!/content/{zirr}/README.sh"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/content\n","Cloning into 'V004_b'...\n","remote: Enumerating objects: 6, done.\u001b[K\n","remote: Counting objects: 100% (6/6), done.\u001b[K\n","remote: Compressing objects: 100% (4/4), done.\u001b[K\n","remote: Total 41 (delta 0), reused 0 (delta 0), pack-reused 35\u001b[K\n","Unpacking objects: 100% (41/41), done.\n","Checking out files: 100% (33/33), done.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Rrz54gSRszv_","colab_type":"code","colab":{}},"source":["deintarle = 3\n","episode = 4\n","\n","fixcolor = 0\n","\n","\n","#===================================\n","DictChormaFix = {\n","    2:(-9,-4,-2),\n","    4:(7,10,-10)\n","                 }\n","\n","\n","zirr = 'V004_b'\n","wrkbase = '/content/'\n","import shutil\n","shutil.rmtree(zirr, ignore_errors=True)\n","\n","\n","\n","import numpy as np\n","import cv2\n","from PIL import Image \n","import os\n","import sys\n","import glob\n","import torch\n","\n","\n","Wr = 0.299\n","Wg = 0.587\n","Wb = 0.114\n","Umax = 0.436\n","Vmax = 0.615\n","\n","scaleYp = 256.0/220.0\n","scaleUVp = 256.0/225.0\n","\n","\n","def RshapeFrame(xfr):\n","  bY = np.array(xfr.planes[0]).reshape((480,768))[:,:720]\n","  bU = np.array(xfr.planes[1]).reshape((480,384))[:240,:360]\n","  bV = np.array(xfr.planes[2]).reshape((480,384))[:240,:360]\n","  return bY,bU,bV\n","\n","def interlace(imgL, imgR, h, w):\n","    inter = np.empty((h, w), imgL.dtype)\n","    inter[:h:2, :w] = imgR[:h:2, :w]\n","    inter[1:h:2, :w] = imgL[1:h:2, :w]\n","    return inter\n","\n","def testpics(starti,typ=0):\n","  vstp = 8\n","  vdir = 'wY'\n","\n","  if typ == 1:\n","    vstp = 10\n","    vdir = 'oY'\n","\n","\n","  showp = vstp*   starti\n","  flist = os.listdir(wrkbase+vdir)\n","  flist.sort()\n","\n","  for i in range(showp,showp+vstp):\n","    print(flist[i])\n","    display(Image.open(wrkbase+vdir+'/'+flist[i]))\n","\n","\n","def toRGB444(fiY,fiU=None,fiV,gshow,slif=None):\n","\n","  usefile = isinstance(fiY, str)\n","  if fiU is None:\n","    if usefile:\n","    else:\n","  else:\n","    if usefile:\n","      tYpl = cv2.imread(fiY, cv2.IMREAD_GRAYSCALE).astype(np.float32)\n","      tUpl = cv2.imread(fiU, cv2.IMREAD_GRAYSCALE).astype(np.float32)\n","      tVpl = cv2.imread(fiV, cv2.IMREAD_GRAYSCALE).astype(np.float32)\n","      tUpl -= 128.0\n","      tVpl -= 128.0\n","    else:\n","      tYpl = fiY\n","      tUpl = fiU\n","      tVpl = fiV\n","\n","\n","  \n","\n","  if slif is not None:\n","    tYpl+=slif[0]\n","    tUpl+=slif[1]\n","    tVpl+=slif[2]\n","\n","\n","  tfR = tYpl + tVpl*(1-Wr)/Vmax\n","  tfG = tYpl - (tUpl*Wb*(1-Wb)/Umax+tVpl*Wr*(1-Wr)/Vmax)/Wg\n","  tfB = tYpl + tUpl*(1-Wb)/Umax\n","\n","  domp = np.transpose(np.asarray([tfR,tfG,tfB]), (1, 2, 0)).clip(0,255.0)\n","\n","  if gshow==1:\n","    print(fiY)\n","    display(Image.fromarray(domp.astype(np.uint8)))\n","  else:\n","    cv2.imwrite(wrkbase+'ottest.png', domp[:,:,[2,1,0]])\n","\n","  return domp\n","  \n","\n","\n","def toRGB422_f(fiY,fiU,fiV,gshow,slif=None):\n","  Ypl = cv2.imread(fiY, cv2.IMREAD_GRAYSCALE).astype(np.float32)\n","  Upl = cv2.imread(fiU, cv2.IMREAD_GRAYSCALE).astype(np.float32)\n","  Vpl = cv2.imread(fiV, cv2.IMREAD_GRAYSCALE).astype(np.float32)\n","\n","  if scaleYUV == 1:\n","    Ypl-=16\n","    Ypl*=scaleYp\n","    Upl-=16\n","    Upl*=scaleUVp\n","    Vpl-=16\n","    Vpl*=scaleUVp\n","\n","  if slif is not None:\n","    tYpl+=slif[0]\n","    tUpl+=slif[1]\n","    tVpl+=slif[2]\n","\n","\n","  Upl -= 128.0\n","  Vpl -= 128.0\n","\n","  Fsiz = toRGB422(Ypl,Upl,Vpl)\n","\n","  domp = np.transpose(Fsiz, (1, 2, 0)).clip(0,255.0)\n","\n","  if gshow==1:\n","    print(fiY)\n","    display(Image.fromarray(domp.astype(np.uint8)))\n","  else:\n","    cv2.imwrite(wrkbase+'ottest422.png', domp[:,:,[2,1,0]])\n","\n","  return domp\n","\n","\n","def toRGB422(tYpl,tUpl,tVpl):\n","  tUpl=np.repeat(tUpl,2,0)\n","  tUpl=np.repeat(tUpl,2,1)\n","  tVpl=np.repeat(tVpl,2,0)\n","  tVpl=np.repeat(tVpl,2,1)\n","\n","\n","\n","  tfR = tYpl + tVpl*(1-Wr)/Vmax\n","  tfG = tYpl - (tUpl*Wb*(1-Wb)/Umax+tVpl*Wr*(1-Wr)/Vmax)/Wg\n","  tfB = tYpl + tUpl*(1-Wb)/Umax\n","\n","  #cv2.imwrite(wrkbase+'ottest422.png', np.transpose(np.asarray([tfB,tfG,tfR]), (1, 2, 0)).clip(0,255.0))\n","\n","  return np.asarray([tfR,tfG,tfB])\n"," \n","def dumpYUV(output,patha):\n","  fY = Wr*output[0]+Wg*output[1]+Wb*output[2]\n","  fU = Umax*(output[2]-fY)/(1-Wb)\n","  fV = Vmax*(output[0]-fY)/(1-Wr)\n","  fU+=0.5\n","  fV+=0.5\n","\n","  cv2.imwrite('/content/2xM/Y/'+patha, fY.clip(0,1)*255.0)\n","  cv2.imwrite('/content/2xM/U/'+patha, fU.clip(0,1)*255.0)\n","  cv2.imwrite('/content/2xM/V/'+patha, fV.clip(0,1)*255.0)\n","\n","\n","\n","scaleYUV = 1\n","\n","colofix = DictChormaFix[episode]"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kyXvSI2AEJfF","colab_type":"text"},"source":["# deinterlace_ffms2"]},{"cell_type":"code","metadata":{"id":"jp_pgj5oIQpT","colab_type":"code","colab":{}},"source":["!sudo apt-get -y install libffms2-4 \n","!pip install ffms2\n","!mkdir wY\n","!mkdir wU\n","!mkdir wV\n","\n","import ffms2\n","\n","\n","vsource = ffms2.VideoSource(wrkbase+'wrk.m2v')\n","fcot = vsource.properties.NumFrames\n","\n","\n","\n","\n","idx=0\n","while idx < fcot:  \n","  bY, bU, bV = RshapeFrame(vsource.get_frame(idx))\n","  if idx%5 == deintarle:\n","    idx+=1\n","    nxbY, nxbU, nxbV = RshapeFrame(vsource.get_frame(idx))\n","    bY = interlace(bY,nxbY,480,720)\n","    bU = interlace(bU,nxbU,240,360)\n","    bV = interlace(bV,nxbV,240,360)\n","  \n","  \n","\n","  strfmt = '%sw%s/x%05d.png' % (wrkbase,'%s',idx)\n","  cv2.imwrite(strfmt % 'Y',bY)\n","  cv2.imwrite(strfmt % 'U',bU)\n","  cv2.imwrite(strfmt % 'V',bV)\n","  idx+=1\n","\n","\n","\n","!mkdir {wrkbase}2x\n","!mkdir {wrkbase}2x/Y\n","!mkdir {wrkbase}2x/U\n","!mkdir {wrkbase}2x/V"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jpxbz90LD9pu","colab_type":"text"},"source":["# deinterlace_ffmpeg"]},{"cell_type":"code","metadata":{"id":"ZLZaOYZxs_2d","colab_type":"code","colab":{}},"source":["!mkdir oY\n","!mkdir oU\n","!mkdir oV\n","!mkdir wY\n","!mkdir wU\n","!mkdir wV\n","!ffmpeg -vsync 0 -i wrk.m2v -filter_complex \"extractplanes=y+u+v[y][u][v]\" -map \"[y]\" 'oY/x%05d.png' -map \"[u]\" 'oU/x%05d.png' -map \"[v]\" 'oV/x%05d.png'"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"BBOxIv1yXl-N","colab_type":"code","colab":{}},"source":["\n","\n","\n","\n","\n","\n","#######################\n","\n","flist = os.listdir(wrkbase+'oY')\n","flist.sort()\n","\n","maefrmY = []\n","maefrmU = []\n","maefrmV = []\n","\n","idx = 0\n","for fi in flist:\n","  gyi = idx%5\n","  if gyi==deintarle:\n","    maefrmY = cv2.imread(wrkbase+'oY/'+fi, cv2.IMREAD_GRAYSCALE).astype(np.uint8)\n","    maefrmU = cv2.imread(wrkbase+'oU/'+fi, cv2.IMREAD_GRAYSCALE).astype(np.uint8)\n","    maefrmV = cv2.imread(wrkbase+'oV/'+fi, cv2.IMREAD_GRAYSCALE).astype(np.uint8)\n","  elif gyi==deintarle+1:\n","    disfrmY = cv2.imread(wrkbase+'oY/'+fi, cv2.IMREAD_GRAYSCALE).astype(np.uint8)\n","    disfrmU = cv2.imread(wrkbase+'oU/'+fi, cv2.IMREAD_GRAYSCALE).astype(np.uint8)\n","    disfrmV = cv2.imread(wrkbase+'oV/'+fi, cv2.IMREAD_GRAYSCALE).astype(np.uint8)\n","\n","    cv2.imwrite(wrkbase+'wY/'+fi,interlace(maefrmY,disfrmY,480,720))\n","    cv2.imwrite(wrkbase+'wU/'+fi,interlace(maefrmU,disfrmU,240,360))\n","    cv2.imwrite(wrkbase+'wV/'+fi,interlace(maefrmV,disfrmV,240,360))\n","  else:\n","    os.link(wrkbase+'oY/'+fi,wrkbase+'wY/'+fi)\n","    os.link(wrkbase+'oU/'+fi,wrkbase+'wU/'+fi)\n","    os.link(wrkbase+'oV/'+fi,wrkbase+'wV/'+fi)\n","\n","  idx+=1\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"o8wWFreqYz69","colab_type":"code","colab":{}},"source":["flist_ms = os.listdir(wrkbase+'wY')\n","flist_ms.sort()\n","\n","\n","#shutil.copy('/content/wYa/x00200.png','/content/wYa/x00100.png')\n","'''\n","flist_pg = os.listdir(wrkbase+'wYa')\n","flist_pg.sort()\n","\n","print(len(flist_ms))\n","print(len(flist_pg))\n","\n","gito = 1538\n","\n","strms = wrkbase+'wY/'+flist_ms[gito+1]\n","strpg = wrkbase+'wYa/'+flist_pg[gito]\n","\n","print(strms)\n","display(Image.open(strms))\n","print(strpg)\n","display(Image.open(strpg))\n","'''\n","\n","flist_ms = flist_ms[10:]\n","\n","for fi in flist_ms:\n","  img_ms = cv2.imread(wrkbase+'wY/'+fi, cv2.IMREAD_GRAYSCALE).astype(np.uint8)\n","  img_pg = cv2.imread(wrkbase+'wYa/'+fi, cv2.IMREAD_GRAYSCALE).astype(np.uint8)\n","  if not (img_ms==img_pg).all():\n","    print('not eq '+fi)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"oAJ3bzpNvaqv","colab_type":"code","colab":{}},"source":["shutil.rmtree('oU', ignore_errors=True)\n","shutil.rmtree('oY', ignore_errors=True)\n","shutil.rmtree('oV', ignore_errors=True)\n","\n","\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"IOOey1LsYnZa","colab_type":"code","colab":{}},"source":["'''\n","shutil.rmtree(wrkbase+'wU', ignore_errors=True)\n","shutil.rmtree(wrkbase+'wY', ignore_errors=True)\n","shutil.rmtree(wrkbase+'wV', ignore_errors=True)\n","!mkdir {wrkbase}wY\n","!mkdir {wrkbase}wU\n","!mkdir {wrkbase}wV\n","'''"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QpSptAE-ESAc","colab_type":"text"},"source":["# SRproc"]},{"cell_type":"code","metadata":{"id":"yDb4xXvSkl7f","colab_type":"code","colab":{}},"source":["testpics(1475)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"dSIJ_rIwtxSA","colab_type":"code","outputId":"8505dcd8-c744-4254-e0e7-f3509e243365","executionInfo":{"status":"ok","timestamp":1581685563408,"user_tz":-480,"elapsed":653,"user":{"displayName":"lamraq ituki","photoUrl":"","userId":"07547115291483367303"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["cd /content/drive/My Drive/TFMLz/ESRGAN_oldarch"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/TFMLz/ESRGAN_oldarch\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"WryXtZqDtdUq","colab_type":"code","colab":{}},"source":["'''\n","import numpy as np\n","import cv2\n","from PIL import Image \n","import os\n","import sys\n","import glob\n","import torch\n","'''\n","\n","from google.colab import files\n","import architecture as arch\n","\n","\n","\n","def mkESRGAN(model_path,scale):\n","\n","  if not os.path.isfile(model_path):\n","    model_path = 'models/'+model_path+'.pth'\n","\n","  \n","  model = arch.RRDB_Net(3, 3, 64, 23, gc=32, upscale=scale, norm_type=None, act_type='leakyrelu', \\\n","                        mode='CNA', res_scale=1, upsample_mode='upconv')\n","  model.load_state_dict(torch.load(model_path), strict=True)\n","  model.eval()\n","  for k, v in model.named_parameters():\n","      v.requires_grad = False\n","  return model\n","\n","\n","\n","\n","\n","\n","\n","flist = os.listdir(wrkbase+'wY')\n","flist.sort()\n","\n","device = torch.device('cuda')  # if you want to run on CPU, change 'cuda' -> cpu\n","####################\n","\n","m4x =  mkESRGAN('DigiPaint35000',4).to(device) #  2x_Faithful_v2_130000_G' '/content/falcoon300.pth'\n","\n","m2x =  mkESRGAN('LADDIER1_282500_G',4).to(device)    #'LADDIER1_282500_G' #'/content/4x_DigitalFrames_2.1.pth'\n","\n","###################\n","\n","#test\n","flist = flist[1475*8:1475*8+100]#flist[1392*8:1392*8+2000]\n","#test\n","\n","\n","for fi in flist:\n","  Ypl = cv2.imread(wrkbase+'wY/'+fi, cv2.IMREAD_GRAYSCALE).astype(np.float32)\n","  Upl = cv2.imread(wrkbase+'wU/'+fi, cv2.IMREAD_GRAYSCALE).astype(np.float32)\n","  Vpl = cv2.imread(wrkbase+'wV/'+fi, cv2.IMREAD_GRAYSCALE).astype(np.float32)\n","\n","  if scaleYUV == 1:\n","    Ypl-=16\n","    Ypl*=scaleYp\n","    Upl-=16\n","    Upl*=scaleUVp\n","    Vpl-=16\n","    Vpl*=scaleUVp\n","\n","\n","  Upl -= 128.0\n","  Vpl -= 128.0\n","\n","\n","  #======mdl2x=========\n","  Fsiz = toRGB422(Ypl,Upl,Vpl)\n","  img = torch.from_numpy(Fsiz/255.0)\n","  img_LR = img.unsqueeze(0)\n","  img_LR = img_LR.to(device)\n","\n","  output = m2x(img_LR).data.squeeze().cpu().numpy() #.squeeze().float().cpu().numpy()\n"," \n","  fY = (Wr*output[0]+Wg*output[1]+Wb*output[2])*255.0\n","\n","  #======mdl2xEND=========\n","\n","  Yplh =  cv2.resize(Ypl, (360, 240), interpolation=cv2.INTER_LINEAR)\n","\n","\n","\n","  #Ypatch = (cv2.resize(Ypl, (1440, 960), interpolation=cv2.INTER_LINEAR)-cv2.resize(Yplh, (1440, 960), interpolation=cv2.INTER_LINEAR))/255.0\n","\n","  Ypatch = (cv2.resize(fY, (1440, 960), interpolation=cv2.INTER_LINEAR)-cv2.resize(Yplh, (1440, 960), interpolation=cv2.INTER_LINEAR))/255.0\n","\n","\n","  fR = Yplh + Vpl*(1-Wr)/Vmax\n","  fG = Yplh - (Upl*Wb*(1-Wb)/Umax+Vpl*Wr*(1-Wr)/Vmax)/Wg\n","  fB = Yplh + Upl*(1-Wb)/Umax\n","\n","  timp = np.asarray([fR,fG,fB])\n","\n","  img = torch.from_numpy(timp/255.0)\n","  img_LR = img.unsqueeze(0)\n","  img_LR = img_LR.to(device)\n","\n","  output = m4x(img_LR).data.squeeze().cpu().numpy() #.squeeze().float().cpu().numpy()\n"," \n","  fY = Wr*output[0]+Wg*output[1]+Wb*output[2]\n","\n","  '''\n","  fU = -0.147*output[0]-0.289*output[1]+0.436*output[2]\n","  fV = 0.615*output[0]-0.515*output[1]-0.100*output[2]\n","  '''\n","\n","  fU = Umax*(output[2]-fY)/(1-Wb)\n","  fV = Vmax*(output[0]-fY)/(1-Wr)\n","\n","  '''\n","  print('Y: '+str(np.max(fY))+', '+str(np.min(fY))+\n","        '\\nU: '+str(np.max(fU))+', '+str(np.min(fU))+\n","        '\\nV: '+str(np.max(fV))+', '+str(np.min(fV)))\n","  '''\n","\n","  fU+=0.5\n","  fV+=0.5\n","  fY+=Ypatch\n","\n","  '''\n","  np.savez_compressed(wrkbase+'2x/Y/'+fi+'.npz', (fY.clip(0,1)*255.0).astype(np.uint8))\n","  np.savez_compressed(wrkbase+'2x/U/'+fi+'.npz', (fU.clip(0,1)*255.0).astype(np.uint8))\n","  np.savez_compressed(wrkbase+'2x/V/'+fi+'.npz', (fV.clip(0,1)*255.0).astype(np.uint8))\n","  '''\n","\n"," \n","  fY*=255.0\n","  fU*=255.0\n","  fV*=255.0\n","\n","  if fixcolor == 1:\n","    fY+=colofix[0]\n","    fU+=colofix[1]\n","    fV+=colofix[2]\n","\n","\n","  fY = cv2.resize(fY, (1080, 720), interpolation=cv2.INTER_LINEAR)\n","  fU = cv2.resize(fU, (1080, 720), interpolation=cv2.INTER_LINEAR)\n","  fV = cv2.resize(fV, (1080, 720), interpolation=cv2.INTER_LINEAR)\n","\n","\n","\n","  cv2.imwrite(wrkbase+'2x/Y/'+fi, fY.clip(0,255))\n","  cv2.imwrite(wrkbase+'2x/U/'+fi, fU.clip(0,255))\n","  cv2.imwrite(wrkbase+'2x/V/'+fi, fV.clip(0,255))\n","  #toRGB444(wrkbase+'2x/Y/'+fi,wrkbase+'2x/U/'+fi,wrkbase+'2x/V/'+fi,gshow=1)\n","\n","\n","\n","  \n","  \n","\n","  #break"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"b3M7_O6oDiQw","colab_type":"code","colab":{}},"source":["fxxi = 'x14800.png'\n","_=toRGB422_f(wrkbase+'wY/'+fxxi,wrkbase+'wU/'+fxxi,wrkbase+'wV/'+fxxi,gshow=1)\n","_=toRGB444(wrkbase+'2x/Y/'+fxxi,wrkbase+'2x/U/'+fxxi,wrkbase+'2x/V/'+fxxi,gshow=1,slif=(0,0,5))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wHcj5W9wS1iw","colab_type":"code","colab":{}},"source":["!7z e '/content/drive/My Drive/TFMLz/ESRGAN_oldarch/models/models.7z' -o/content\n","#falcoon300.7z\n","#detoon.rar"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"MO7irmSI0CpF","colab_type":"code","colab":{}},"source":["#print(os.listdir(wrkbase+'4x'))\n","#from google.colab import files\n","#files.download(wrkbase+'wU/x00001.png')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0Z07HIjY0zim","colab_type":"code","colab":{}},"source":["!mkdir {wrkbase}oY\n","!cp {wrkbase}oYr/0155*.pgm {wrkbase}oY"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"t09P4RnqhOPR","colab_type":"text"},"source":["# OLDarch"]},{"cell_type":"code","metadata":{"id":"o66-kA7E7EaP","colab_type":"code","colab":{}},"source":["#!pip3 install numpy opencv-python\n","#!pip3 install torch torchvision\n","mkdir /content/sample_data/img"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Irj6v_VBrEAW","colab_type":"code","outputId":"5e859ef3-c235-424a-ba9e-94db6c3e89cb","executionInfo":{"status":"ok","timestamp":1581179897692,"user_tz":-480,"elapsed":1736,"user":{"displayName":"lamraq ituki","photoUrl":"","userId":"07547115291483367303"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["cd /content/drive/My Drive/TFMLz/ESRGAN_oldarch"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/TFMLz/ESRGAN_oldarch\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"P331xaYjss1w","colab_type":"code","outputId":"8736ca1d-dd25-4e21-bb6b-10de55814caa","executionInfo":{"status":"ok","timestamp":1580145054129,"user_tz":-480,"elapsed":3691,"user":{"displayName":"lamraq ituki","photoUrl":"","userId":"07547115291483367303"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["import sys\n","import os.path\n","import glob\n","import cv2\n","import numpy as np\n","import torch\n","import architecture as arch\n","\n","\n","device = torch.device('cuda')  # if you want to run on CPU, change 'cuda' -> cpu\n","\n","test_img_folder = '/content/sample_data/img/*'\n","\n","#!wget -P /content/sample_data/img/ http://muryouav.avximg.com/2018-05/upload/86fb6f00e0550fbf1d784d485ac7df3c516e2140.jpg\n","\n","\n","model_path = '4x_Spongebob_v6_190000_G' #2x_Faithful_v2_130000_G'\n","\n","model = arch.RRDB_Net(3, 3, 64, 23, gc=32, upscale=4, norm_type=None, act_type='leakyrelu', \\\n","                        mode='CNA', res_scale=1, upsample_mode='upconv')\n","model.load_state_dict(torch.load('models/'+model_path+'.pth'), strict=True)\n","model.eval()\n","for k, v in model.named_parameters():\n","    v.requires_grad = False\n","model = model.to(device)\n","\n","#print('Model path {:s}. \\nTesting...'.format(model_path))\n","\n","idx = 0\n","for path in glob.glob(test_img_folder):\n","    idx += 1\n","    base = os.path.splitext(os.path.basename(path))[0]\n","    print(idx, base)\n","    # read image\n","    img = cv2.imread(path, cv2.IMREAD_COLOR)\n","    img = img * 1.0 / 255\n","    img = torch.from_numpy(np.transpose(img[:, :, [2, 1, 0]], (2, 0, 1))).float()\n","    img_LR = img.unsqueeze(0)\n","    img_LR = img_LR.to(device)\n","\n","    output = model(img_LR).data.squeeze().float().cpu().clamp_(0, 1).numpy()\n","    output = np.transpose(output[[2, 1, 0], :, :], (1, 2, 0))\n","    output = (output * 255.0).round()\n","    cv2.imwrite('results/{:s}'.format(base)+'_'+model_path+'.png', output)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["1 mmg\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"FgdsmGxihSGf","colab_type":"text"},"source":["# CurArch"]},{"cell_type":"code","metadata":{"id":"a1HOY5rihW9X","colab_type":"code","outputId":"c998d3d9-0c62-4f2f-8668-a4f86974c3d0","executionInfo":{"status":"ok","timestamp":1578677943492,"user_tz":-480,"elapsed":1160,"user":{"displayName":"lamraq ituki","photoUrl":"","userId":"07547115291483367303"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["cd /content/drive/My Drive/TFMLz/ESRGAN"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/TFMLz/ESRGAN\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"SF5Eil7VhlXt","colab_type":"code","colab":{}},"source":["import os.path as osp\n","import glob\n","import cv2\n","import numpy as np\n","import torch\n","import RRDBNet_arch as arch\n","import sys\n","\n","model_path = 'RRDB_ESRGAN_x4'\n","device = torch.device('cuda')  # if you want to run on CPU, change 'cuda' -> cpu\n","# device = torch.device('cpu')\n","\n","!wget -P /content/sample_data/img/ http://img.eromenskan.com/wp-content/uploads/gazo/575/073_20140118185830ab5.jpg\n","\n","test_img_folder = '/content/sample_data/img/*'\n","\n","model = arch.RRDBNet(3, 3, 64, 23, gc=32)\n","model.load_state_dict(torch.load('models/'+model_path+'.pth'), strict=True)\n","model.eval()\n","model = model.to(device)\n","\n","print('Model path {:s}. \\nTesting...'.format(model_path))\n","\n","idx = 0\n","for path in glob.glob(test_img_folder):\n","    idx += 1\n","    base = osp.splitext(osp.basename(path))[0]\n","    print(idx, base)\n","    # read images\n","    img = cv2.imread(path, cv2.IMREAD_COLOR)\n","    img = img * 1.0 / 255\n","    img = torch.from_numpy(np.transpose(img[:, :, [2, 1, 0]], (2, 0, 1))).float()\n","    img_LR = img.unsqueeze(0)\n","    img_LR = img_LR.to(device)\n","\n","    with torch.no_grad():\n","        output = model(img_LR).data.squeeze().float().cpu().clamp_(0, 1).numpy()\n","    output = np.transpose(output[[2, 1, 0], :, :], (1, 2, 0))\n","    output = (output * 255.0).round()\n","    cv2.imwrite('results/{:s}'.format(base)+'_'+model_path+'.png', output)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ELIa4Fj7ld0D","colab_type":"text"},"source":["# SloMo2019"]},{"cell_type":"code","metadata":{"id":"Io7Az8VYlisX","colab_type":"code","colab":{}},"source":["import modelz\n","import datas\n","import configs\n","\n","from PIL import Image\n","import torch\n","import torchvision\n","import torchvision.transforms as TF\n","import torch.optim as optim\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import time\n","import os\n","from math import log10\n","import numpy as np\n","import datetime\n","from utils.config import Config\n","import sys\n","\n","import time\n","\n","import cv2\n","\n","# loading configures\n","\n","\n","# args = parser.parse_config()\n","\n","config = Config.from_file('configs/config_test.py')\n","\n","# preparing datasets\n","normalize1 = TF.Normalize(config.mean, [1.0, 1.0, 1.0])\n","normalize2 = TF.Normalize([0, 0, 0], config.std)\n","trans = TF.Compose([TF.ToTensor(), normalize1, normalize2, ])\n","\n","revmean = [-x for x in config.mean]\n","revstd = [1.0 / x for x in config.std]\n","revnormalize1 = TF.Normalize([0.0, 0.0, 0.0], revstd)\n","revnormalize2 = TF.Normalize(revmean, [1.0, 1.0, 1.0])\n","revNormalize = TF.Compose([revnormalize1, revnormalize2])\n","\n","revtrans = TF.Compose([revnormalize1, revnormalize2]) #TF.ToPILImage()\n","\n","testset = datas.MySequence(config.testset_root, trans, config.test_size, config.test_crop_size, config.inter_frames)\n","sampler = torch.utils.data.SequentialSampler(testset)\n","validationloader = torch.utils.data.DataLoader(testset, sampler=sampler, batch_size=1, shuffle=False, num_workers=1)\n","\n","\n","# model\n","model = getattr(modelz, config.model)(config.pwc_path).cuda()\n","model = nn.DataParallel(model)\n","\n","tot_time = 0\n","tot_frames = 0\n","\n","print('Everything prepared. Ready to test...')\n","\n","\n","\n","!mkdir /content/2xM\n","!mkdir /content/2xM/Y\n","!mkdir /content/2xM/U\n","!mkdir /content/2xM/V\n","\n","rg1 = range(1)\n","rg2 = range(2)\n","\n","def generate():\n","    global tot_time, tot_frames\n","    retImg = []\n","   \n","    \n","\n","    vrgg = rg1\n","    vrgk = 1\n","    \n","\n","    with torch.no_grad():\n","        for validationIndex, validationData in enumerate(validationloader, 0):\n","            sample, psyh = validationData\n","\n","            naubase = psyh[0][0]\n","            frame0 = sample[0]\n","            frame1 = sample[1]\n","            frame2 = sample[2]\n","            frame3 = sample[3]\n","\n","            #print(str(frame0.dtype)+',lay='+str(frame0.layout))\n","            #print(frame0)\n","\n","            I0 = frame0.cuda()\n","            I3 = frame3.cuda()\n","\n","            I1 = frame1.cuda()\n","            I2 = frame2.cuda()\n","\n","            \n","            print(naubase)\n","            revtrans(I0.clone().cpu()[0]) #.save(svba)\n","            #dumpYUV(vymg,naubase)\n","            os.link('/content/2x/Y/'+naubase,'/content/2xM/Y/'+naubase)\n","            os.link('/content/2x/U/'+naubase,'/content/2xM/U/'+naubase)\n","            os.link('/content/2x/V/'+naubase,'/content/2xM/V/'+naubase)\n","\n","            \n","                \n","            \n","\n","            \n","            for tt in vrgg:\n","                x = config.inter_frames\n","                t = 1.0/(x+1) * (tt + 1)\n","                #print(t)\n","\n","\n","                # record duration time\n","                start_time = time.time()\n","\n","                output = model(I0, I1, I2, I3, t)\n","                It_warp = output\n","                \n","                tot_time += (time.time() - start_time)\n","                tot_frames += 1\n","                \n","\n","                \n","                vymg2 = revtrans(It_warp.cpu()[0]).numpy()\n","                dumpYUV(vymg2,psyh[1][0]+ '_' + str(tt) + '.png')\n","\n","\n","\n","\n","            \n","            if vrgk==1:\n","              vrgk = 2\n","              vrgg = rg2\n","            elif vrgk == 2:\n","              vrgk = 1\n","              vrgg = rg1\n","               \n","               \n","                    \n","def test():\n","\n","    dict1 = torch.load(config.checkpoint)\n","    model.load_state_dict(dict1['model_state_dict'])\n","\n","   \n","    generate()\n","\n","\n","test()\n","\n","print ('Avg time is {} second'.format(tot_time/tot_frames))\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"NglB5wO0LCCW","colab_type":"code","colab":{}},"source":["flist = os.listdir('/content/2xM/Y')\n","flist.sort()\n","\n","\n","\n","idx = 1\n","for fi in flist:\n","  vopng = '%05d.png' % idx\n","  os.rename('/content/2xM/Y/'+fi,'/content/2xM/Y/'+vopng)\n","  os.rename('/content/2xM/U/'+fi,'/content/2xM/U/'+vopng)\n","  os.rename('/content/2xM/V/'+fi,'/content/2xM/V/'+vopng)\n","  idx+=1"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xhGeLV3fAkYs","colab_type":"text"},"source":["# To2160"]},{"cell_type":"code","metadata":{"id":"ruiArr1KAoke","colab_type":"code","colab":{}},"source":["flist = os.listdir(wrkbase+'2xM/Y')\n","flist.sort()\n","\n","\n","\n","device = torch.device('cuda')  # if you want to run on CPU, change 'cuda' -> cpu\n","####################\n","\n","\n","\n","m2x =  mkESRGAN('/content/4x_DigitalFrames_2.1.pth',4).to(device)    #'LADDIER1_282500_G'\n","\n","for fi in flist:\n","  Ypl = cv2.imread(wrkbase+'2xM/Y/'+fi, cv2.IMREAD_GRAYSCALE).astype(np.float32)\n","  Upl = cv2.imread(wrkbase+'2xM/U/'+fi, cv2.IMREAD_GRAYSCALE).astype(np.float32)\n","  Vpl = cv2.imread(wrkbase+'2xM/V/'+fi, cv2.IMREAD_GRAYSCALE).astype(np.float32)\n","\n","  Upl -= 128.0\n","  Vpl -= 128.0\n","\n","  fR = Ypl + Vpl*(1-Wr)/Vmax\n","  fG = Ypl - (Upl*Wb*(1-Wb)/Umax+Vpl*Wr*(1-Wr)/Vmax)/Wg\n","  fB = Ypl + Upl*(1-Wb)/Umax\n","\n","  timp = np.asarray([fR,fG,fB])\n","\n","  img = torch.from_numpy(timp/255.0)\n","  img_LR = img.unsqueeze(0)\n","  img_LR = img_LR.to(device)\n","\n","  output = m2x(img_LR).data.squeeze().cpu().numpy()\n"," \n","  fY = Wr*output[0]+Wg*output[1]+Wb*output[2]\n","  fU = Umax*(output[2]-fY)/(1-Wb)\n","  fV = Vmax*(output[0]-fY)/(1-Wr)\n","\n","  fU+=0.5\n","  fV+=0.5\n","\n","  fY*=255.0\n","  fU*=255.0\n","  fV*=255.0\n","\n","  fY = cv2.resize(fY, (2960, 2160), interpolation=cv2.INTER_LINEAR)\n","  fU = cv2.resize(fU, (1480, 1080), interpolation=cv2.INTER_LINEAR)\n","  fV = cv2.resize(fV, (1480, 1080), interpolation=cv2.INTER_LINEAR)\n","\n","  #fY/=scaleYp\n","  #fY+=16\n","\n","  fU/=scaleUVp\n","  fV/=scaleUVp\n","\n","  #fU+=16\n","  #fV+=16\n","\n","  cv2.imwrite(wrkbase+'2xM/Y/'+fi, fY.clip(0,255))\n","  cv2.imwrite(wrkbase+'2xM/U/'+fi, fU.clip(0,255))\n","  cv2.imwrite(wrkbase+'2xM/V/'+fi, fV.clip(0,255))\n","  \n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ih3MgQTYviM-","colab_type":"code","outputId":"3482d49a-5488-4cf5-98b8-92d021ef5db6","executionInfo":{"status":"ok","timestamp":1581698477314,"user_tz":-480,"elapsed":273170,"user":{"displayName":"lamraq ituki","photoUrl":"","userId":"07547115291483367303"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["!ffmpeg -framerate 60 -f image2 -i /content/2xM/Y/%05d.png -framerate 60 -f image2 -i /content/2xM/U/%05d.png -framerate 60 -f image2 -i /content/2xM/V/%05d.png -filter_complex \"[0][1][2]mergeplanes=0x001020:yuv420p,pad=3840:2160:0:0:black\" -c:v libx264 -crf 5 -shortest izo.mkv"],"execution_count":0,"outputs":[{"output_type":"stream","text":["ffmpeg version 3.4.6-0ubuntu0.18.04.1 Copyright (c) 2000-2019 the FFmpeg developers\n","  built with gcc 7 (Ubuntu 7.3.0-16ubuntu3)\n","  configuration: --prefix=/usr --extra-version=0ubuntu0.18.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --enable-gpl --disable-stripping --enable-avresample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librubberband --enable-librsvg --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-omx --enable-openal --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libopencv --enable-libx264 --enable-shared\n","  libavutil      55. 78.100 / 55. 78.100\n","  libavcodec     57.107.100 / 57.107.100\n","  libavformat    57. 83.100 / 57. 83.100\n","  libavdevice    57. 10.100 / 57. 10.100\n","  libavfilter     6.107.100 /  6.107.100\n","  libavresample   3.  7.  0 /  3.  7.  0\n","  libswscale      4.  8.100 /  4.  8.100\n","  libswresample   2.  9.100 /  2.  9.100\n","  libpostproc    54.  7.100 / 54.  7.100\n","Input #0, image2, from '/content/2xM/Y/%05d.png':\n","  Duration: 00:00:04.03, start: 0.000000, bitrate: N/A\n","    Stream #0:0: Video: png, gray(pc), 2960x2160, 60 tbr, 60 tbn, 60 tbc\n","Input #1, image2, from '/content/2xM/U/%05d.png':\n","  Duration: 00:00:04.03, start: 0.000000, bitrate: N/A\n","    Stream #1:0: Video: png, gray(pc), 1480x1080, 60 fps, 60 tbr, 60 tbn, 60 tbc\n","Input #2, image2, from '/content/2xM/V/%05d.png':\n","  Duration: 00:00:04.03, start: 0.000000, bitrate: N/A\n","    Stream #2:0: Video: png, gray(pc), 1480x1080, 60 fps, 60 tbr, 60 tbn, 60 tbc\n","Stream mapping:\n","  Stream #0:0 (png) -> mergeplanes:in0\n","  Stream #1:0 (png) -> mergeplanes:in1\n","  Stream #2:0 (png) -> mergeplanes:in2\n","  pad -> Stream #0:0 (libx264)\n","Press [q] to stop, [?] for help\n","\u001b[0;35m[image2 @ 0x564c02e66c00] \u001b[0m\u001b[0;33mThread message queue blocking; consider raising the thread_queue_size option (current value: 8)\n","\u001b[0m\u001b[0;35m[image2 @ 0x564c02e67800] \u001b[0m\u001b[0;33mThread message queue blocking; consider raising the thread_queue_size option (current value: 8)\n","\u001b[0m\u001b[1;36m[libx264 @ 0x564c02e30a00] \u001b[0musing cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2\n","\u001b[1;36m[libx264 @ 0x564c02e30a00] \u001b[0mprofile High, level 5.2\n","\u001b[1;36m[libx264 @ 0x564c02e30a00] \u001b[0m264 - core 152 r2854 e9a5903 - H.264/MPEG-4 AVC codec - Copyleft 2003-2017 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=3 lookahead_threads=1 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=25 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=5.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n","Output #0, matroska, to 'izo.mkv':\n","  Metadata:\n","    encoder         : Lavf57.83.100\n","    Stream #0:0: Video: h264 (libx264) (H264 / 0x34363248), yuv420p, 3840x2160, q=-1--1, 60 fps, 1k tbn, 60 tbc (default)\n","    Metadata:\n","      encoder         : Lavc57.107.100 libx264\n","    Side data:\n","      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: -1\n","\u001b[0;35m[image2 @ 0x564c02e66000] \u001b[0m\u001b[0;33mThread message queue blocking; consider raising the thread_queue_size option (current value: 8)\n","frame=  242 fps=0.9 q=-1.0 Lsize=  256230kB time=00:00:03.98 bitrate=526865.8kbits/s speed=0.0147x    \n","video:256226kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.001476%\n","\u001b[1;36m[libx264 @ 0x564c02e30a00] \u001b[0mframe I:16    Avg QP: 6.55  size:1733213\n","\u001b[1;36m[libx264 @ 0x564c02e30a00] \u001b[0mframe P:65    Avg QP:10.01  size:1231339\n","\u001b[1;36m[libx264 @ 0x564c02e30a00] \u001b[0mframe B:161   Avg QP:10.45  size:960287\n","\u001b[1;36m[libx264 @ 0x564c02e30a00] \u001b[0mconsecutive B-frames:  9.1%  5.0%  5.0% 81.0%\n","\u001b[1;36m[libx264 @ 0x564c02e30a00] \u001b[0mmb I  I16..4: 25.5% 41.8% 32.7%\n","\u001b[1;36m[libx264 @ 0x564c02e30a00] \u001b[0mmb P  I16..4:  1.7% 47.8% 18.9%  P16..4:  1.8%  4.0%  2.8%  0.0%  0.0%    skip:22.9%\n","\u001b[1;36m[libx264 @ 0x564c02e30a00] \u001b[0mmb B  I16..4:  0.9% 24.9% 15.2%  B16..8: 11.0% 10.8%  5.8%  direct: 7.8%  skip:23.6%  L0:35.2% L1:34.0% BI:30.9%\n","\u001b[1;36m[libx264 @ 0x564c02e30a00] \u001b[0m8x8 transform intra:61.6% inter:47.7%\n","\u001b[1;36m[libx264 @ 0x564c02e30a00] \u001b[0mcoded y,uvDC,uvAC intra: 96.5% 96.5% 96.1% inter: 48.9% 49.1% 28.8%\n","\u001b[1;36m[libx264 @ 0x564c02e30a00] \u001b[0mi16 v,h,dc,p: 69%  5% 12% 14%\n","\u001b[1;36m[libx264 @ 0x564c02e30a00] \u001b[0mi8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 20%  9% 22%  6%  9% 10%  7%  9%  8%\n","\u001b[1;36m[libx264 @ 0x564c02e30a00] \u001b[0mi4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 20% 11% 10%  8% 13% 12%  9% 10%  8%\n","\u001b[1;36m[libx264 @ 0x564c02e30a00] \u001b[0mi8c dc,h,v,p: 48% 10% 25% 17%\n","\u001b[1;36m[libx264 @ 0x564c02e30a00] \u001b[0mWeighted P-Frames: Y:0.0% UV:0.0%\n","\u001b[1;36m[libx264 @ 0x564c02e30a00] \u001b[0mref P L0: 41.6% 21.1% 19.6% 17.8%\n","\u001b[1;36m[libx264 @ 0x564c02e30a00] \u001b[0mref B L0: 88.8%  9.1%  2.1%\n","\u001b[1;36m[libx264 @ 0x564c02e30a00] \u001b[0mref B L1: 94.5%  5.5%\n","\u001b[1;36m[libx264 @ 0x564c02e30a00] \u001b[0mkb/s:520412.44\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"fOOiQs6k3Z_7","colab_type":"code","colab":{}},"source":["from google.colab import files\n","files.download('/content/2xM/Y/00025.png')\n","#import shutil\n","#shutil.rmtree('/content/2xM', ignore_errors=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0cmJlTLkZ7xX","colab_type":"code","colab":{}},"source":["antopo = os.listdir('/content/2xM/Y')\n","antopo.sort()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"3zxdFrrnaCst","colab_type":"code","colab":{}},"source":["nstai = 18\n","nitopo = antopo[nstai:nstai+4]\n","\n","for fxxi in nitopo:\n","  _=toRGB444('/content/2xM/Y/'+fxxi,'/content/2xM/U/'+fxxi,'/content/2xM/V/'+fxxi,gshow=1)#,slif=DictChormaFix[4])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"WVTvh0mRI6x9","colab_type":"code","colab":{}},"source":["shutil.rmtree('/content/2xM', ignore_errors=True)"],"execution_count":0,"outputs":[]}]}
